<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ljh2000</title>
  <icon>http://ljh2000.github.io/messi.jpg</icon>
  
  <link href="http://ljh2000.github.io/atom.xml" rel="self"/>
  
  <link href="http://ljh2000.github.io/"/>
  <updated>2023-02-13T08:04:26.211Z</updated>
  <id>http://ljh2000.github.io/</id>
  
  <author>
    <name>ljh2000</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>OCR-free Document Understanding Transformer</title>
    <link href="http://ljh2000.github.io/2023/02/13/OCR-free-Document-Understanding-Transformer/"/>
    <id>http://ljh2000.github.io/2023/02/13/OCR-free-Document-Understanding-Transformer/</id>
    <published>2023-02-13T07:28:15.000Z</published>
    <updated>2023-02-13T08:04:26.211Z</updated>
    
    <content type="html"><![CDATA[<p>ECCV2022</p><p>不依赖OCR的视觉文档理解Transformer，能实现文档分类、文档信息提取、VQA等多项任务</p><p>论文链接：<a href="https://arxiv.org/pdf/2111.15664v5.pdf">OCR-freeDocument Understanding Transformer</a></p><p>Github链接：<a href="https://github.com/clovaai/donut">donut</a></p><p><img src="/2023/02/13/OCR-free-Document-Understanding-Transformer/1.png"></p><span id="more"></span><h2 id="abstract">Abstract</h2><p>Understanding document images (e.g., invoices) is a core butchallenging task since it requires complex functions such as readingtext and a holistic understanding of the document. Current VisualDocument Understanding (VDU) methods outsource the task of reading textto off- the-shelf Optical Character Recognition (OCR) engines and focuson the understanding task with the OCR outputs. Although such OCR-basedapproaches have shown promising performance, they suffer from 1) highcomputational costs for using OCR; 2) inflexibility of OCR models onlanguages or types of documents; 3) OCR error propagation to the sub-sequent process. To address these issues, in this paper, we introduce anovel OCR-free VDU model named Donut, which stands for Documentunderstanding transformer. As the first step in OCR-free VDU research,we propose a simple architecture (i.e., Transformer) with a pre-trainingobjective (i.e., cross-entropy loss). Donut is conceptually simple yetef- fective. Through extensive experiments and analyses, we show asimple OCR-free VDU model, Donut, achieves state-of-the-art performanceson various VDU tasks in terms of both speed and accuracy. In addition,we offer a synthetic data generator that helps the model pre-training tobe flexible in various languages and domains. The code, trained model,and synthetic data are available athttps://github.com/clovaai/donut.</p><h2 id="introduction">Introduction</h2><p>视觉文档理解（VDU）的任务目标是从文档图像中提取出有用的信息，其具体任务包括文档分类、文档信息提取和视觉问题回答（VQA）等。现有的大部分VDU模型一般使用两阶段方案来解决这一问题：1、读取文档图像中的文本;2、对文件的整体理解。这些VDU模型高度依赖OCR引擎完成由图像到文档文本的转换任务，并在读取得到的文档文本基础上完成文本理解建模。</p><p>这一做法存在一些问题：</p><ul><li>使用OCR作为预处理方法的代价很高。通常的策略是使用预训练好的现成的OCR引擎，但对于高性能的OCR模型，推理的计算成本非常高。</li><li>现有的OCR方法很难处理不同语言或领域变化，这可能导致泛化能力较差。重新训练一个OCR模型，也需要大量的训练成本和大规模的数据集。</li><li>OCR识别的错误会传播到VDU系统，并对后续文档理解进程产生负面影响（有一些方法引入了OCR纠错模块，但在实际应用中会增大系统开销，增加模型复杂度）。</li></ul><p><img src="/2023/02/13/OCR-free-Document-Understanding-Transformer/2.png"></p><p>本文在没有OCR的前提下，实现了端到端建模，能直接完成从原始输入图像到下游任务所需输出的映射，有效解决了传统的VDU问题对OCR的依赖问题。</p><h2 id="method">Method</h2><p>Donus：Document understandingtransformer，模型架构简单，由一个基于Transformer的visualencoder和一个文本decoder组成。</p><h3 id="encoder">Encoder</h3><p>编码器将输入的文档图像转换为一组嵌入 <span class="math inline">\(\{z_i|z_i \in R^d,1 \le i \len\}\)</span>，其中，n为特征图的大小或 image patches 的数量，d为编码器的隐层向量维数。本文选取了 Swin Transformer 作为主干网络。</p><h3 id="decoder">Decoder</h3><p>对于编码器得到的嵌入，解码器生成一个 token sequence，表示第 i 个token 的 one-hot 向量。本文使用 BART 作为解码器架构。</p><h3 id="pre-training">Pre-training</h3><p>预训练阶段模型被训练为从左上到右下的阅读顺序，通过前一文本和当前图像来联合预测下一个文本内容，并最小化交叉熵损失。</p><h3 id="synthdog">SynthDoG</h3><p>对于上述合成数据，作者设计了一种数据合成的范式SynthDoG，将文档分为背景、文档纹理、文本、布局四个组件。</p><h3 id="fine-tuning">Fine-tuning</h3><p>微调阶段需要教模型如何理解文档图像，本文将所有下游任务解释为一个 JSON预测问题。</p><p>解码器被训练为生成一个令牌序列，该令牌序列可以转换为表示所需输出信息的JSON 。例如，在文档分类任务中，解码器被训练生成一个令牌序列 [STARTclass][memo][END class]，它是1对1可逆的 JSON {"class": "memo"}。</p><h2 id="experiments-and-analyses">Experiments and Analyses</h2><p>Document Classification</p><p><img src="/2023/02/13/OCR-free-Document-Understanding-Transformer/3.png"></p><p>Document Information Extraction</p><p><img src="/2023/02/13/OCR-free-Document-Understanding-Transformer/4.png"></p><p>Document Visual Question Answering</p><p><img src="/2023/02/13/OCR-free-Document-Understanding-Transformer/5.png"></p><p><img src="/2023/02/13/OCR-free-Document-Understanding-Transformer/6.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;ECCV2022&lt;/p&gt;
&lt;p&gt;不依赖OCR的视觉文档理解Transformer，能实现文档分类、文档信息提取、VQA等多项任务&lt;/p&gt;
&lt;p&gt;论文链接：&lt;a href=&quot;https://arxiv.org/pdf/2111.15664v5.pdf&quot;&gt;OCR-free
Document Understanding Transformer&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Github链接：&lt;a href=&quot;https://github.com/clovaai/donut&quot;&gt;donut&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/13/OCR-free-Document-Understanding-Transformer/1.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Paper" scheme="http://ljh2000.github.io/categories/Paper/"/>
    
    
    <category term="VQA" scheme="http://ljh2000.github.io/tags/VQA/"/>
    
    <category term="Visual Document Understanding" scheme="http://ljh2000.github.io/tags/Visual-Document-Understanding/"/>
    
  </entry>
  
  <entry>
    <title>A Unified Generative Framework based on Prompt Learning for Various Information Extraction Tasks</title>
    <link href="http://ljh2000.github.io/2023/02/07/A-Unified-Generative-Framework-based-on-Prompt-Learning-for-Various-Information-Extraction-Tasks/"/>
    <id>http://ljh2000.github.io/2023/02/07/A-Unified-Generative-Framework-based-on-Prompt-Learning-for-Various-Information-Extraction-Tasks/</id>
    <published>2023-02-07T11:08:42.000Z</published>
    <updated>2023-02-11T13:35:52.981Z</updated>
    
    <content type="html"><![CDATA[<p>论文链接：<a href="https://arxiv.org/pdf/2209.11570v1.pdf">A UnifiedGenerative Framework based on Prompt Learning for Various InformationExtraction Tasks</a></p><p>本文提出了一种基于prompt的生成式框架CPGF，可以用于各种信息抽取任务。</p><p><img src="/2023/02/07/A-Unified-Generative-Framework-based-on-Prompt-Learning-for-Various-Information-Extraction-Tasks/1.png"></p><span id="more"></span><h2 id="abstract">Abstract</h2><p>Prompt learning is an effective paradigm that bridges gaps betweenthe pre-training tasks and the corresponding downstream applications.Approaches based on this paradigm have achieved great transcendentresults in various applications. However, it still needs to be answeredhow to design a unified framework based on the prompt learning paradigmfor various information extraction tasks. In this paper, we propose anovel composable prompt-based generative framework, which could beapplied to a wide range of tasks in the field of InformationExtraction.Specifically, we reformulate information extraction tasksinto the form of filling slots in pre-designed type-specific prompts,which consist of one or multiple sub-prompts.A strategy of constructingcomposable prompts is proposed to enhance the generalization ability toextract events in data-scarce scenarios. Furthermore, to fit thisframework, we transform Relation Extraction into the task of determiningsemantic consistency in prompts. The experimental results demonstratethat our approach surpasses compared baselines on real-world datasets indata-abundant and data-scarce scenarios. Further analysis of theproposed framework is presented, as well as numerical experimentsconducted to investigate impact factors of performance on varioustasks.</p><h2 id="background">Background</h2><p>传统信息抽取方法大多基于Fine-tuning，针对下游任务精心设计网络结构，但是至少有两个因素会产生预训练和微调之间不可忽略的gap：</p><ul><li>采用额外的网络会导致预训练和微调的结构化差异</li><li>预训练任务和下游任务存在显著差异</li></ul><p>Prompt Learning 能有效解决预训练与微调的不一致问题，在 Prompt范式下，下游任务都能转换为与预训练任务类似的形式。</p><p>本文在信息提取领域提出了一个新的统一的基于提示的生成框架（CPGF）。CPGF将各种IE任务转换为完形填空任务，并用T5 来预测输出。</p><p>本文的贡献如下：</p><ul><li><p>本文提出了一个基于提示学习范式的新型统一生成框架，用于各种信息抽取任务。</p></li><li><p>本文介绍了一种为复杂任务（如EE）构建独立子提示的方法。此外，为了提高框架在数据稀缺的情况下提取事件的通用能力，为事件提取设计了一种由多个模块化子提示组成的可组合提示。</p></li><li><p>本文提出了一种基于提示的方法，通过判断语义矛盾来实现关系抽取，并为其设计了一个相应的模板。</p></li><li><p>一系列关于EE、NER和RE的实验结果表明，该框架在数据丰富和数据稀缺的情况下都很有效。</p></li></ul><h2 id="method">Method</h2><p>CPGF框架包含四个部分：</p><ul><li><p><strong>TaskFormalization</strong>：形式化信息提取任务，将复杂信息做片段分解。</p></li><li><p><strong>Sub-Prompts Generation</strong>：生成各信息片段的子提示Sub-prompts。</p></li><li><p><strong>Prompts Construction</strong>：构建提示。</p></li><li><p><strong>Answer Generation</strong>：采用 T5 预测答案。</p></li></ul><h3 id="task-formalization">Task Formalization</h3><ul><li><p>原始文本<span class="math inline">\(S\)</span></p></li><li><p>目标信息<span class="math inline">\(\mathcal{Y}=\{\mathcal{Y}^1,\cdots,\mathcal{Y}^t\}\)</span></p><ul><li><p><span class="math inline">\(\mathcal{Y}^j\)</span>表示类型<span class="math inline">\(j\)</span>的待提取信息，<span class="math inline">\(t\)</span>为类型总数</p></li><li><p>对于EE任务，<span class="math inline">\(\mathcal{Y}^j\)</span>可能包含多个元素，如事件类型和论元角色</p></li></ul></li><li><p>提示<span class="math inline">\(Pr=\{Pr^1,\cdots,Pr^t\}\)</span></p></li></ul><h3 id="sub-prompts-generation">Sub-Prompts Generation</h3><p>依赖于类型的子提示适用于数据丰富的场景，而模块化的子提示是为数据稀缺的场景设计的。</p><p>图的左边部分显示了依赖类型的子提示和信息类别之间的关系，子提示是通过用掩码词替换每个信息类型的定义或片段描述中的关键词而独立产生的。</p><p><img src="/2023/02/07/A-Unified-Generative-Framework-based-on-Prompt-Learning-for-Various-Information-Extraction-Tasks/2.png"></p><p>在使用模块化子提示的情况下，我们在产生子提示之前合并类似的信息片段。CPGF将具有相同语义但分布在不同类型信息中的元素视为同一信息片段。通过分析训练数据集中的信息元素的语义，手工建立了一个涵盖每种信息类型的所有组成的信息片段库。数据集中的每一类信息都由库中的一个或多个信息片段组成。</p><p>我们通过为信息片段库中的每个元素生成一个与类型无关的子提示，组成一个模块化的子提示库<span class="math inline">\(P=\{p_1,p_2,\cdots,p_{\lvertF\rvert}\}\)</span>，其中<span class="math inline">\(\lvertF\rvert\)</span>表示信息片段的总数。详细地说，它在一个描述片段和信息类型之间关系的通用句子中替换了关键词，以获得一个模块化的子提示。我们的框架通过从模块化子提示库中搜索其片段来获得目标信息的子提示。通过这种方式，CPGF可以有效地提取具有从未见过的类型的信息元素，如果这些元素出现在片段库中。</p><h3 id="prompts-construction">Prompts Construction</h3><p>第<span class="math inline">\(j\)</span>种信息类型的提示是通过连接原始文本和子提示来构建的：<span class="math display">\[\begin{align}\mathcal{S}_{\text{prompt}}^j &amp;= f_{\text{prompt}}(S) \\                          &amp;= S \mathop{\Vert} Pr^j\end{align}\]</span></p><p>其中<span class="math inline">\(\mathop\Vert\)</span>表示拼接两段文本，<span class="math inline">\(Pr^j\)</span>表示组合目标信息中所有相关元素的子提示：</p><p><span class="math display">\[Pr^j = \mathop{\Vert}_{i=1}^n p_i^j\]</span></p><p>对于NER和RE，<span class="math inline">\(n\)</span>始终为1。对于EE，<span class="math inline">\(S^j_{\text{promt}}\)</span>被称为特定类型的prompt，如果用来组成的提示语是依赖于类型的，因为这个提示语的每个部分都与信息类型有关。由模块化子提示组成的提示被命名为"可组合提示"。</p><h3 id="answer-generation">Answer Generation</h3><p><img src="/2023/02/07/A-Unified-Generative-Framework-based-on-Prompt-Learning-for-Various-Information-Extraction-Tasks/3.png"></p><p>在获得样本的一系列提示后，将其送入PLM，通过MLM预测每个提示中MASK词的预测值。<span class="math display">\[z_i^j = \text{MLM}(p_i^j)\]</span> 在这个过程中，使用特殊字符 <span class="math inline">\(\vert\)</span> 分隔子提示的多个答案。</p><h2 id="reference">Reference</h2><p>Fromhttps://entropy2333.github.io/2022/10/15/A-Unified-Generative-Framework-based-on-Prompt-Learning-for-Various-Information-Extraction-Tasks</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;论文链接：&lt;a href=&quot;https://arxiv.org/pdf/2209.11570v1.pdf&quot;&gt;A Unified
Generative Framework based on Prompt Learning for Various Information
Extraction Tasks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文提出了一种基于prompt的生成式框架
CPGF，可以用于各种信息抽取任务。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/07/A-Unified-Generative-Framework-based-on-Prompt-Learning-for-Various-Information-Extraction-Tasks/1.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Paper" scheme="http://ljh2000.github.io/categories/Paper/"/>
    
    
    <category term="Prompt" scheme="http://ljh2000.github.io/tags/Prompt/"/>
    
  </entry>
  
  <entry>
    <title>ParchCore - Towards Total Recall in Industrial Anomaly Detection</title>
    <link href="http://ljh2000.github.io/2022/11/10/ParchCore-Towards-Total-Recall-in-Industrial-Anomaly-Detection/"/>
    <id>http://ljh2000.github.io/2022/11/10/ParchCore-Towards-Total-Recall-in-Industrial-Anomaly-Detection/</id>
    <published>2022-11-10T01:25:33.000Z</published>
    <updated>2023-02-01T10:24:47.884Z</updated>
    
    <content type="html"><![CDATA[<p>CVPR2022</p><p>工业界异常检测，应用于冷启动场景，PatchCore采用离群点检测，实现异常检测与定位。</p><p>论文链接：<a href="https://arxiv.org/abs/2106.08265v1">Towards TotalRecall in Industrial Anomaly Detection</a></p><p><img src="/2022/11/10/ParchCore-Towards-Total-Recall-in-Industrial-Anomaly-Detection/1.png"></p><span id="more"></span><h2 id="abstract">Abstract</h2><p>Being able to spot defective parts is a critical component inlarge-scale industrial manufacturing. A particular challenge that weaddress in this work is the cold-start problem: fit a model usingnominal (non-defective) example images only. While handcrafted solutionsper class are possible, the goal is to build systems that work wellsimultaneously on many different tasks automatically. The best peformingapproaches combine embeddings from ImageNet models with an outlierdetection model. In this paper, we extend on this line of work andpropose PatchCore, which uses a maximally representative memory bank ofnominal patchfeatures. PatchCore offers competitive inference timeswhile achieving state-of-the-art performance for both detection andlocalization. On the challenging, widely used MVTec AD benchmarkPatchCore achieves an image-level anomaly detection AUROC score of up to99.6%, more than halving the error compared to the next best competitor.We further report competitive results on two additional datasets andalso find competitive results in the few samples regime. Code:github.com/amazon-research/patchcore-inspection.</p><h2 id="introduction">Introduction</h2><ul><li>最大化正常样本的信息量</li><li>冷启动场景</li><li>coreset subsampling 能提取最有代表性的集合且推断速度很高</li></ul><h2 id="method">Method</h2><h3 id="local-aware-patch-features">Local aware patch features</h3><ul><li><p>训练时采用正常样本，即 <span class="math inline">\(\forall x\in\chi _N: y_x=0\)</span>；测试样本：<span class="math inline">\(\forallx\in \chi _T: y_x \in \{0,1\}\)</span></p></li><li><p><span class="math inline">\(\phi\)</span> 为<code>ImageNet</code>上预训练好的网络，<span class="math inline">\(\phi_{i,j}=\phi_j(x_i)\)</span> 表示输入图片 <span class="math inline">\(x_i\)</span> 网络 <span class="math inline">\(\phi\)</span> 第 j 层的输出特征，特征图上的点即<span class="math inline">\(\phi_{i,j}(h,w)=\phi_j(x_i,h,w)\)</span></p></li><li><p>本文提出用感受野更大的 patch-level，而非特征图上的点</p></li><li><p><code>neighbourhood</code>：</p><p><span class="math display">\[\begin{align}N_p^{(h,w)} = \{(a,b)|&amp; a\in [h-\lfloor p/2 \rfloor],...,h+\lfloor p/2 \rfloor],\\ &amp;b\in[w-\lfloor p/2 \rfloor,...,w+\lfloor p/2 \rfloor ]\}\end{align}\]</span></p></li><li><p><code>local aware features</code> at position (h,w)： <span class="math display">\[\phi_{i,j}(N_P^{h,w})=f_{agg}(\{ \phi_{i,j}(a,b) | (a,b)\in N_p^{h,w}\})\]</span></p></li><li><p><code>locally aware patch-feature collection</code>： <span class="math display">\[P_{s,p}(\phi_{i,j}) = \{ \phi_{i,j}(N_P^{h,w}) |\ h,w \ mod\ s=0\}\]</span></p></li><li><p><code>Memory bank</code>：以一个点为中心计算其邻居点集，得到的特征值集合<span class="math display">\[M=\bigcup_{x_i \in \chi_N} P_{s,p}(\phi_j(x_i))\]</span></p></li></ul><p>​</p><h3 id="coreset-reduced-patch-feature-memory-bank">Coreset-reducedpatch-feature memory bank</h3><ul><li><p><code>Memory Bank</code>太大，需要缩小。若直接随机采样会丧失重要信息。为了提升检测效率，作者采用<code>greedy coreset subsampling</code> 来选取最具代表性的特征点集合<code>M-coreset</code>：，缩减特征池的大小，在降低推理时间的同时保证性能（<code>coreset selection</code>一般指寻找原集合的一个子集，能在尽量接近原集合的情况下，大幅提高原集合上的运算速度）：<span class="math display">\[M_C^*=\arg\ \min_{M_C \subset M}\ \max_{m \in M}\ \min_{n \in M_C}\ ||m-n ||_2\]</span></p></li><li><p><span class="math inline">\(M_C^*\)</span> 的准确计算是<code>NP-Hard</code>，考虑贪心算法，首先任意取一个子集，计算集合 <span class="math inline">\(M\)</span>每一个点到子集的距离（点到集合的距离定义为该点到集合内所有点的最小距离），即<span class="math inline">\(||m-n||_2\)</span>，<span class="math inline">\(\max\)</span> 指在 <span class="math inline">\(M\)</span>中找到距离子集最大的点，最终求得距离集合 <span class="math inline">\(M\)</span> 最近的集合 <span class="math inline">\(M_C^*\)</span>：</p><p><img src="/2022/11/10/ParchCore-Towards-Total-Recall-in-Industrial-Anomaly-Detection/2.png"></p></li></ul><h3 id="anomaly-detection-with-patchcore">Anomaly Detection withPatchCore</h3><ul><li>根据训练集得到 <code>Memory Bank</code> 即 <span class="math inline">\(M\)</span> 之后，对于测试图片 <span class="math inline">\(x^{test}\)</span>，计算测试图片的<code>patch-feature</code>，得到 <span class="math inline">\(m^{test}\)</span>。计算 <span class="math inline">\(P(x^{test})\)</span> 到集合<span class="math inline">\(M\)</span>的距离，并找到距离最远的点 <span class="math inline">\(m^{test,*}\)</span>，其中，<span class="math inline">\(arg\min\)</span> 计算的是点 <span class="math inline">\(m^{test}\)</span> 到集合 <span class="math inline">\(M\)</span> 的距离，然后找到距离最远的点 <span class="math inline">\(m^{test,*}\)</span>：</li></ul><p><span class="math display">\[m^{test,*},m^* = arg\max_{m_{test} \in P(x^{test})} \ arg \min_{m \in M}||m^{test}-m||_2 \\\]</span></p><p><span class="math display">\[s^*=||m^{test,*}-m^*||_2\]</span></p><ul><li>在 <span class="math inline">\(m*\)</span> 的最近点集，计算分数，求<span class="math inline">\(softmax\)</span>： <span class="math display">\[s = (1-\frac{exp||m^{test,*}-m^*||_2}{\sum_{m\inN_b(m^*)}exp||m^{test,*}-m||_2})\]</span></li></ul><p>考虑<code>local neighborhood aggregation</code>操作，可以理解为<code>average pooling</code>，实现时采用一个窗口大小为3(kernel size)，步长为 1(stride)，padding为1的 <code>AvgPool2d</code>实现，能在不损失空间分辨率的同时，增大感受野</p><h2 id="experiments">Experiments</h2><ul><li>AUROC</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;CVPR2022&lt;/p&gt;
&lt;p&gt;工业界异常检测，应用于冷启动场景，PatchCore
采用离群点检测，实现异常检测与定位。&lt;/p&gt;
&lt;p&gt;论文链接：&lt;a href=&quot;https://arxiv.org/abs/2106.08265v1&quot;&gt;Towards Total
Recall in Industrial Anomaly Detection&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2022/11/10/ParchCore-Towards-Total-Recall-in-Industrial-Anomaly-Detection/1.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Paper" scheme="http://ljh2000.github.io/categories/Paper/"/>
    
    
    <category term="Anomaly Detection" scheme="http://ljh2000.github.io/tags/Anomaly-Detection/"/>
    
  </entry>
  
  <entry>
    <title>Intro to NLP</title>
    <link href="http://ljh2000.github.io/2022/10/27/Intro-to-NLP/"/>
    <id>http://ljh2000.github.io/2022/10/27/Intro-to-NLP/</id>
    <published>2022-10-27T15:28:08.000Z</published>
    <updated>2022-12-26T18:35:55.130Z</updated>
    
    <content type="html"><![CDATA[<p>学习笔记</p><p>《自然语言处理入门》 何晗著 人民邮电出版社</p><span id="more"></span><h1 id="chapter-1-intro">Chapter 1 Intro</h1><p>Introduction</p><p>hanlp</p><h1 id="chapter-2-词典分词">Chapter 2 词典分词</h1><h2 id="词典与切分算法">词典与切分算法</h2><p>1、齐夫定律：单词的词频与词频排名成反比</p><p>2、幂律分布（长尾效应）</p><p>3、完全切分：遍历文本中连续序列，查询序列是否在词典中（输出所有可能的单词）</p><p>4、正向最长匹配：从前往后扫描，优先输出更长的单词（单词越长优先度越高）</p><p>5、逆向最长匹配：从后往前扫描，保留最长单词</p><p>6、双向最长匹配：</p><ul><li>同时执行正向和逆向最长匹配，若两者的词数不同，则返回词数更少的那一个</li><li>否则，返回两者中单字更少的那一个。当单字数也相同时，优先返回逆向最长匹配的结果。</li></ul><h2 id="字典树与-ac-自动机">字典树与 AC 自动机</h2><p>1、字典树（trie树、前缀树）</p><ul><li>字典树中每条边对应一个字</li><li>从根节点往下的路径构成字符串</li><li>根节点完美散列，其余节点用二分查找（仅在根节点实现散列策略，普通节点维护数组的有序性，基于数组实现二分查找）</li></ul><p>2、双数组字典树（DAT）：base/check 双数组</p><ul><li><p>常规字典树，<span class="math inline">\(c\)</span>个子节点时，每次状态转移的复杂度为 <span class="math inline">\(O(\logc)\)</span></p></li><li><p>当状态 b 接受字符 c 转移到状态 p 时： <pre class="language-python" data-language="python"><code class="language-python">p <span class="token operator">=</span> base<span class="token punctuation">[</span>b<span class="token punctuation">]</span> <span class="token operator">+</span> ccheck<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> base<span class="token punctuation">[</span>b<span class="token punctuation">]</span></code></pre></p></li><li><p>单次状态转移的时间复杂度都是常数</p></li></ul><h2 id="ac自动机">AC自动机</h2><p>1、AC 自动机</p><ul><li><p>DAT 实现全切分的复杂度为 <span class="math inline">\(O(n^2)\)</span>，AC自动机一次扫描就能查询出所有的单词，广泛用于多字符串搜索</p></li><li><p>多模式匹配：给定多个词语（模式串），从母文本中匹配它们</p></li><li><p>AC 自动机为前缀树上的每个节点建立一棵后缀树：</p><ul><li>goto表：将每个模式串索引到前缀树上，根节点还接受任意其他字符并转移到自己</li><li>output 表：从初始状态到当前状态的路径本身对应的模式串 +路径的后缀所对应的模式串</li><li>fail表：存储状态转移失败后回退的最佳状态，即能记住已匹配上的字符串的最长后缀那个状态，构造fail表：<ul><li>初始状态的 goto 表满，故无 fail 指针，与初始状态直连的所有状态，fail指针指向初始状态</li><li>从初始状态开始 <span class="math inline">\(BFS\)</span>，若 S接受字符 c 直达 T，则设 <span class="math inline">\(T.fail\)</span> 为<span class="math inline">\(S.fail\)</span> 中第一个接受 c不为空的状态F，否则一直向上跳 fail 指针回溯</li><li>由上可知，F 是 T 的后缀，故 <span class="math inline">\(T.output +=F.output\)</span></li></ul></li></ul></li></ul><p>2、基于 DAT 的 AC 自动机</p><ul><li>替换 AC 自动机的 goto 表即可</li><li>在 DAT 的基础上引入 <span class="math inline">\(output[i][]\)</span>和 <span class="math inline">\(fail[i]\)</span></li></ul><h1 id="chapter-3-二元语法与中文分词">Chapter 3 二元语法与中文分词</h1><h2 id="语言模型">语言模型</h2><p>1、语料库与技术统计</p><p>2、语言模型</p><ul><li><p>以单词列表的形式建模句子，单词列表 $ w=w_1 w_2 ...w_k$，</p></li><li><p>语言模型：<span class="math inline">\(p(w) = p(w_1 w_2 ... w_k) =p(w_1 | w_0) \times p(w_2|w_0 w_1) \times ... \times p(w_{k+1}|w_0w_1...w_k)=\prod_{t=1}^{k+1}p(w_t|w_0 w_1...w_{t-1})\)</span></p></li><li><p><span class="math inline">\(w_0=BOS,&lt;s&gt;\)</span>；<span class="math inline">\(w_{k+1}=EOS,&lt;/s&gt;\)</span></p></li><li><p>根据语料库，使用极大似然估计（MLE）可计算每个后验概率，其中，<span class="math inline">\(c(w_0...w_t)\)</span>表示计数： <span class="math display">\[p(w_{t}|w_0 w_1...w_{t-1})=p_{ML}(w_{t}|w_0w_1...w_{t-1})=\frac{c(w_0...w_t)}{c(w_0...w_{t-1})}\]</span></p></li><li><p>数据稀疏问题：长度越大的句子越难出现（实际遇到的句子大部分都在语料库之外），语料库难以统计到长句子的频次；计算代价大</p></li></ul><p>3、马尔科夫链</p><ul><li><p>马尔科夫假设：只考虑前一个单词；可构成二元语法模型： <span class="math display">\[p(w)=\prod_{t=1}^{k+1}p(w_t|w_{t-1}）\]</span></p></li><li><p>n 元语法：仅考虑 n 个单词。然而，n越大，数据稀疏问题越严峻</p></li><li><p>数据稀疏与平滑策略：利用低阶n元语法平滑高阶n元语法</p></li></ul><h2 id="中文分词语料库">中文分词语料库</h2><p>1、《人民日报》 语料库PKU</p><p>2、微软亚洲研究院语料库MSR</p><p>3、繁体中文分词语料库：CITYU、AS</p><h2 id="训练与预测">训练与预测</h2><p>1、训练定义：训练（train）指的是，给定样本集（dataset，训练所用的样本集称为训练集）估计模型参数的过程</p><p>2、预测定义：预测（predict）指的是利用模型对样本（句子）进行推断的过程</p><p>3、词网与词图：</p><ul><li>词网指的是句子中所有一元语法构成的网状结构，将句子中所有单词找出来。起始位置（offset）相同的单词写作一行</li><li>词网第 i 行中长 l 的单词与第 i+l行的所有单词互相连接，构成一个“词图”<br></li><li>节点距离计算</li><li>维特比算法</li></ul><h1 id="chapter-4-隐马尔可夫模型与序列标注">Chapter 4隐马尔可夫模型与序列标注</h1><h2 id="序列标注问题">序列标注问题</h2><p>1、序列标注：给定序列 x，给出序列中每个元素对应的标签 y；对于 y的所有的可能取值集合称为标注集</p><p>2、中文分词：Begin、End、Middle、Single</p><p>3、词性标注</p><p>4、命名实体识别：复合词，地名、机构等</p><h2 id="隐马尔科夫模型">隐马尔科夫模型</h2><p>1、隐马尔可夫模型（Hidden Markov Model，HMM）是描述两个时序序列联合分布 𝑝(𝒙, 𝒚)的概率模型，满足马尔科夫假设</p><ul><li>𝒙序列外界可见（外界指的是观测者）， 称为观测序列（observationsequence），观测 𝑥 为单词</li><li>𝒚序列外界不可见，称为状态序列（state sequence），状态 𝑦 为词性<br></li><li>人们也称状态为隐状态（hidden state），而称观测为显状态（visiblestate）<br></li><li>马尔可夫假设：每个事件的发生概率只取决于前一个事件<ul><li>将满足该假设的连续多个事件串联在一起，就构成了马尔可夫链</li><li>隐马尔可夫模型理解起来就并不复杂了：它的马尔可夫假设作用于状态序列</li><li>假设1：当前状态 <span class="math inline">\(y_t\)</span>仅仅依赖于前一个状态 <span class="math inline">\(y_{t-1}\)</span>，连续多个状态构成隐马尔可夫链𝒚</li><li>假设2：任意时刻的观测 <span class="math inline">\(x_t\)</span>只依赖于该时刻的状态 <span class="math inline">\(y_t\)</span>，与其他时刻的状态或观测独立无关<br></li></ul></li><li>隐马尔可夫模型利用三个要素来模拟时序序列的发生过程<ul><li>初始状态概率向量：系统启动时进入的第一个状态</li><li>状态转移概率矩阵：状态转移的概率矩阵</li><li>发射概率矩阵（也称作观测概率矩阵）：给定每种 𝑦， 𝑥都是一个独立的离散型随机变量，其参数对应一个向量</li></ul></li><li>隐马尔科夫模型的三种用法：样本生成问题、模型训练问题、序列预测问题</li></ul><p>2、隐马尔科夫模型的样本生成</p><ul><li><p>医疗诊断</p></li><li><p>样本生成算法：考虑长 T的样本序列，它的生成过程就是沿着隐马尔可夫链走 T 步</p></li></ul><p>3、隐马尔科夫模型的训练</p><ul><li>极大似然法估计模型参数</li></ul><p>4、隐马尔科夫模型的预测</p><ul><li>概率计算的前向算法</li><li>搜索状态序列的维特比算法</li></ul><p>5、隐马尔可夫模型的基本问题有三个</p><ul><li>样本生成</li><li>参数估计</li><li>序列预测</li></ul><h1 id="chapter-5-感知机分类与序列标注">Chapter 5感知机分类与序列标注</h1><h2 id="分类问题">分类问题</h2><p>1、分类（classification）指的是预测样本所属类别的一类问题</p><h2 id="线性分类模型与感知机算法">线性分类模型与感知机算法</h2><p>1、线性模型</p><p>2、特征向量、特征提取、特征函数</p><p>3、决策边界与分离超平面</p><p>4、感知机算法</p><p>5、损失函数与梯度下降</p><h2 id="结构化预测问题">结构化预测问题</h2><p>1、结构化预测（structuredprediction）则是预测对象结构的一类监督学习问题</p><ul><li>相应的模型训练过程称作结构化学习（structured learning）</li><li>自然语言处理中有许多任务都是结构化预测<ul><li>比如序列标注预测结构是一整个序列</li><li>句法分析预测结构是一棵句法树</li><li>机器翻译预测结构是一段完整的译文</li></ul></li><li>结构化预测的过程就是给定一个模型及打分函数score，利用打分函数给一些备选结构打分，选择分数最高的结构作为预测输出</li></ul><h2 id="结构化感知机">结构化感知机</h2><p>1、序列标注</p><p>2、维特比解码算法</p><h1 id="chapter-6-条件随机场与序列标注">Chapter 6条件随机场与序列标注</h1><h2 id="机器学习的模型谱系">机器学习的模型谱系</h2><figure><img src="/2022/10/27/Intro-to-NLP/Users\ljh2000\AppData\Roaming\Typora\typora-user-images\image-20221227014938149.png" alt="image-20221227014938149"><figcaption aria-hidden="true">image-20221227014938149</figcaption></figure><p>1、生成式/判别式模型</p><p>2、有向与无向概率图模型</p><h2 id="条件随机场">条件随机场</h2><p>1、条件随机场：条件随机场（Conditional Random Field，CRF）是一种给定输入随机变量 x， 求解条件概率 p(y ∣x)的概率无向图模型</p><p>2、线性链条件随机场</p><p>3、条件随机场的训练</p><p>4、对比结构化感知机</p><ul><li>特征函数相同、权重向量相同、打分函数相同、预测算法相同、同属结构化学习<br></li><li>最大的不同点在于训练算法</li></ul><h2 id="条件随机场工具包-crf">条件随机场工具包 CRF++</h2><p>日本奈良先端科学技术大学院大学的工藤拓所开发的CRF++</p><h1 id="chapter-7-词性标注">Chapter 7 词性标注</h1><h2 id="词性标注概述">词性标注概述</h2><p>1、词性</p><ul><li><p>词性（Part-Of-Speech，POS）指的是单词的语法分类，也称为词类。同一个类别的词语具有相似的语法性质</p></li><li><p>所有词性的集合称为词性标注集。</p></li><li><p>用处：当下游应用遇到OOV时，可以通过OOV的词性猜测用法；词性也可以直接用于抽取一些信息，比如抽取所有描述特定商品的形容词等</p></li></ul><p>2、词性标注指的的是为句子中每个单词预测一个词性标签的任务</p><p>3、词性标注模型</p><h2 id="词性标注语料库与标注集">词性标注语料库与标注集</h2><p>1、人民日报》 语料库与PKU标注集</p><p>2、国家语委语料库与863标注集</p><p>3、《诛仙》 语料库与CTB标注集</p><h2 id="序列标注模型应用于词性标注">序列标注模型应用于词性标注</h2><p>1、基于隐马尔科夫模型</p><p>2、基于感知机</p><p>3、基于条件随机场</p><p>4、词性标注评测</p><h2 id="自定义词性">自定义词性</h2><p>1、自定义词性：在工程上，许多用户希望将特定的一些词语打上自定义的标签</p><p>2、词典匹配、标注领域语料</p><h1 id="chapter8-命名实体识别">Chapter8 命名实体识别</h1><h2 id="命名实体识别概述">命名实体识别概述</h2><p>1、命名实体（namedentity）：文本中有一些描述实体的词汇，比如人名、地名、组织机构名、股票基金、医学术语等</p><p>2、命名实体识别（Named Entity Recognition，NER）：识别出句子中命名实体的边界与类别的任务</p><ul><li>对于规则性较强的命名实体，完全可以通过正则表达式处理</li><li>对于较短的命名实体，比如人名，完全可以通过分词确定边界，通过词性标注模块确定类别</li><li>在另一些语料库中（如PKU等），机构名这样的复合词是拆开的，此时就需要一个专门的命名实体识别模块了</li></ul><p>3、基于规则的命名实体识别</p><h2 id="命名实体识别语料库">命名实体识别语料库</h2><p>1、1998年《人民日报》 语料库</p><p>2、微软命名实体识别语料库</p><h2 id="基于层叠隐马尔可夫模型的角色标注框架">基于层叠隐马尔可夫模型的角色标注框架</h2><p>1、基于层叠隐马尔可夫模型的角色标注框架</p><ul><li>该框架的识别思路与日本人名的思路类似：为构成命名实体的短词语打标签，标签序列满足某种模式则识别为某种命名实体</li><li>角色标注模块的输入是分词模块的输出，两个模块都由隐马尔可夫模型驱动，所以称为层叠隐马尔可夫模型</li></ul><h2 id="基于序列标注的命名实体识别">基于序列标注的命名实体识别</h2><p>1、命名实体的边界可以通过{B, M, E,S}确定，其类别可以通过B-nt等附加类别的标签来确定</p><p>2、特征提取</p><p>3、基于隐马尔可夫模型序列标注的命名实体识别</p><p>4、基于感知机序列标注的命名实体识别</p><p>5、基于条件随机场序列标注的命名实体识别</p><p>6、命名实体识别标准化评测</p><ul><li>P</li><li>R</li><li>F1</li></ul><h1 id="chapter-9-信息抽取">Chapter 9 信息抽取</h1><h2 id="新词提取">新词提取</h2><p>1、新词：词典之外的词语（也就是未登录词OOV）</p><p>2、基本原理</p><ul><li>提取出大量文本（生语料）中的词语，无论新旧；</li><li>用词典过滤掉已有的词语，于是得到新词</li></ul><p>3、信息熵</p><p>4、互信息</p><h2 id="关键词提取">关键词提取</h2><p>1、词频</p><p>2、TF-IDF</p><ul><li>TF-IDF(t,d) = TF(t,d) / DF(t) = TF(t,d) * IDF(t)</li><li>t 为单词，d 为文档，TF(t,d) 表示 t 在 d 的频次；DF(t)表示有多少篇文档包含 t，DF 的倒数称为 IDF</li></ul><p>3、TextRank</p><ul><li>PageRank在文本上的应用</li><li>PageRank将互联网看作有向图，互联网上的网页视作节点，迭代更新权重S(Vi)</li><li>将PageRank应用到关键词提取，将单词视作节点而已，每个单词的外链来自自身前后固定大小的窗口内的所有单词</li></ul><h2 id="短语提取">短语提取</h2><p>1、短语提取</p><ul><li>将新词提取中的“字符”替换为“单词”，马上得到短语提取</li><li>注意先过滤停用词才能得到更好的效果</li></ul><h2 id="关键句提取">关键句提取</h2><p>1、改进链接的BM25权重计算</p><ul><li>窗口的中心句与相邻的句子间的链接有强有弱，相似的句子将得到更高的投票<br></li><li>BM25(D,Q)</li></ul><p>2、TextRank</p><ul><li>以BM25相似度作为PageRank中的链接的权重，于是得到一种改进算法，称为TextRank<br></li><li>WS(Vi)</li></ul><h1 id="chapter-10-文本聚类">Chapter 10 文本聚类</h1><h2 id="聚类">聚类</h2><p>1、聚类（clusteranalysis）指的是将给定对象的集合划分为不同子集的过程</p><ul><li>这些子集又被称为簇（cluster），一般没有交集</li></ul><p>2、根据元素从属于集合的确定程度，聚类分为硬聚类和软聚类。</p><ul><li>硬聚类（hard clustering）</li><li>软聚类（soft clustering）</li></ul><p>3、聚类的应用：数据预处理、排重、大众化推荐、人工抽查</p><p>4、文本聚类：对文档进行的聚类分析，改善搜索结果、生成同义词</p><h2 id="文档的特征提取">文档的特征提取</h2><p>1、词袋模型：词袋（bag-of-words）是信息检索与自然语言处理中最常用的文档表示模型，它将文档想象为一个装有词语的袋子，通过袋子中每种词语的计数等统计量将文档表示为向量</p><p>2、词袋统计指标</p><ul><li>布尔词频：词频非零的话截取为1，否则为0。</li><li>TF-IDF：将每个词语的倒排频次也纳入考虑。</li><li>词向量</li><li>定义由 n 个文档组成的集合为 S，定义其中第 i 个文档 di 的特征向量为<span class="math inline">\(d_i\)</span>，其计算方式如下： <span class="math inline">\(d_i =(TF(t_1,d_i),TF(t_2,d_i),...,TF(t_j,d_i),...,TF(t_m,d_i))\)</span></li><li>其中 <span class="math inline">\(t_j\)</span> 表示词表中第 <span class="math inline">\(j\)</span> 种单词， <span class="math inline">\(m\)</span> 为词表大小。<span class="math inline">\(TF(t_j,d_i)\)</span> 表示单词 <span class="math inline">\(t_j\)</span> 在文档 di中的出现次数，缩放向量使得<span class="math inline">\(||d||=1\)</span></li></ul><h2 id="k均值算法">k均值算法</h2><p>1、基本原理</p><p>2、初始质心的选取</p><p>3、更快的准则函数</p><h2 id="重复二分聚类算法">重复二分聚类算法</h2><p>1、重复二分聚类（repeated bisection clustering）是k均值算法的效率加强版，其名称中的bisection是“二分”的意思，指的是反复对子集进行二分</p><p>2、基本原理</p><h2 id="标准化评测">标准化评测</h2><p>1、P、R、F1</p><p>2、语料库</p><p>3、评测实验</p><h1 id="chapter-11-文本分类">Chapter 11 文本分类</h1><h2 id="文本分类概念">文本分类概念</h2><p>1、文本分类（text classification），又称文档分类（documentclassification），指的是将一个文档归类到一个或多个类别中的自然语言处理任务</p><ul><li>垃圾邮件过滤</li><li>垃圾评论过滤</li><li>自动标签</li><li>情感分析</li></ul><p>2、文本的类别（category或class）有时又称标签（label），所有类别组成一个标注集</p><p>3、文本分类语料库</p><h2 id="文本分类的特征提取">文本分类的特征提取</h2><p>1、分词</p><p>2、卡方特征选择</p><p>3、词袋向量</p><h2 id="朴素贝叶斯分类器">朴素贝叶斯分类器</h2><p>1、朴素贝叶斯原理</p><p>2、朴素贝叶斯文本分类器</p><h2 id="支持向量机分类器">支持向量机分类器</h2><p>1、支持向量机（Support Vector Machine，SVM）是一种二分类模型，其学习策略在于如何找出一个决策边界，使得边界到正负样本的最小距离都最远</p><p>2、线性支持向量机</p><h2 id="标准化评测-1">标准化评测</h2><p>1、P、R、F1</p><h2 id="情感分析">情感分析</h2><p>1、文本情感分析指的是提取文本中的主观信息的一种NLP任务，其具体目标通常是找出文本所对应的正负情感态度</p><ul><li>情感分析可以在实体、句子、段落乃至文档上进行</li></ul><p>2、情感分析语料库</p><p>3、训练情感分析模型</p><h1 id="chapter-12-依存句法分析">Chapter 12 依存句法分析</h1><h2 id="短语结构树">短语结构树</h2><p>1、语言满足复合性原理（principle of compositionality）</p><ul><li>在数学、语义学和语言哲学中，复合性原理是指，一个复杂表达式的意义是由其各组成部分的意义以及用以结合它们的规则来决定的</li></ul><p>2、上下文无关文法（context-free grammar， CFG），它由如下组件构成：</p><ul><li>终结符（terminal symbol， 无法再分的最小单位）集合 <span class="math inline">\(\sum\)</span>， 比如汉语的一个词表。</li><li>非终结符（nonterminal symbol）集合V，比如“名词短语”“动词短语”等短语结构组成的集合。V中至少包含一个特殊的非终结符，即句子符或初始符，记作 <span class="math inline">\(S\in V\)</span>。</li><li>推导规则 R，即推导非终结符的一系列规则：<span class="math inline">\(V-&gt; V+\sum\)</span> 。比如S→名词短语，以及名词短语→名词+名词短语，和名词短语→名词+名词。</li></ul><p>3、短语结构树</p><h2 id="依存句法树">依存句法树</h2><p>1、依存句法树关注的是句子中词语之间的语法联系，并且将其约束为树形结构</p><p>2、依存句法理论</p><ul><li>依存语法理论认为词与词之间存在主从关系，这是一种二元不等价的关系</li><li>如果一个词修饰另一个词，则称修饰词为从属词（dependent），被修饰的词语称为支配词（head），两者之间的语法关系称为依存关系（dependencyrelation）<br></li><li>将一个句子中所有词语的依存关系以有向边的形式表示出来，就会得到一棵树，称为依存句法树（dependencyparse tree）</li><li>4个约束性的公理。<ul><li>有且只有一个词语（ROOT，虚拟根节点，简称虚根）不依存于其他词 语。根节点唯一性</li><li>除此之外所有单词必须依存于其他单词。 连通</li><li>每个单词不能依存于多个单词。 无环</li><li>如果单词A依存于B，那么位置处于A和B之间的单词C只能依存于A、B或AB之间的单词。投射性（projective）</li></ul></li></ul><p>3、中文依存句法树库</p><h2 id="依存句法分析">依存句法分析</h2><p>1、依存句法分析（dependencyparsing）指的是分析句子的依存语法的一种中高级NLP任务，其输入通常是词语和词性，输出则是一棵依存句法树</p><p>2、基于图的依存句法分析</p><ul><li>依存句法树其实是完全图（completegraph，每对顶点都相连的图）的一个子图</li><li>为完全图中的每条边属于句法树与否的可能性打分</li><li>利用Prim之类的算法找出最大生成树（MST）作为依存句法树</li></ul><p>3、基于转移的依存句法分析</p><h2 id="基于转移的依存句法分析">基于转移的依存句法分析</h2><p>1、Arc-Eager转移系统</p><p>2、特征提取</p><p>3、Static和Dynamic Oracles</p><p>4、Dynamic Oracle与感知机在线学习</p><p>5、柱搜索</p><h1 id="chapter-13-深度学习与自然语言处理">Chapter 13深度学习与自然语言处理</h1><h2 id="传统方法的局限">传统方法的局限</h2><p>1、传统方法贵在精简，难在表示效果差</p><p>2、数据稀疏</p><p>3、特征模板</p><p>4、误差传播</p><h2 id="深度学习与优势">深度学习与优势</h2><p>1、深度学习（Deep Learning， DL） 属于表示学习（RepresentationLearning）的范畴，指的是利用具有一定“深度”的模型来自动学习事物的向量表示（vectorialrepresentation）的一种学习范式。目前，深度学习所采用的模型主要是层数在一层以上的神经网络。通过多层感知机提取向量才是深度学习的精髓</p><p>2、用稠密向量解决数据稀疏</p><p>3、用多层网络自动提取特征表示</p><p>4、端到端的设计</p><h2 id="word2vec">word2vec</h2><p>1、连接传统机器学习与深度学习的桥梁</p><p>2、CBOW</p><p>3、训练词向量</p><p>4、单词语义相似度</p><p>5、词语类比</p><p>6、短文本相似度</p><h2 id="基于神经网络的高性能依存句法分析器">基于神经网络的高性能依存句法分析器</h2><p>1、Arc-Standard转移系统</p><p>2、特征提取</p><h2 id="自然语言处理进阶">自然语言处理进阶</h2><p>1、两个常用的特征提取器</p><ul><li>用于时序数据的递归神经网络RNN</li><li>用于空间数据的卷积神经网络CNN</li></ul><p>2、词嵌入预训练</p><ul><li>fastText</li><li>ELMo</li><li>Contexutal String Embedding</li></ul><p>3、基于Transformer的预训练语言模型</p><ul><li>GPT</li><li>BERT<ul><li>RoBERT</li><li>ALBERT</li></ul></li><li>XLNet</li></ul><p>4、序列标注</p><ul><li>BiLSTM-CRF</li><li>Flair</li></ul><p>5、依存分析</p><ul><li>BiAffineAttention</li><li>BiAffineAttention+BERT</li></ul><p>6、自动问答和文档摘要等，在深度学习时代反而显得非常简单</p><p>7、许多QA任务归结为衡量问题和备选答案之间的文本相似度</p><p>8、文档摘要涉及的文本生成技术，又恰好是RNN语言模型所擅长的</p><p>9、机器翻译领域，Google早已利用基于神经网络的机器翻译技术淘汰了基于短语的机器翻译技术</p><p>10、总体上，自然语言处理已经由过去的特征工程转变为结构工程</p><p>11、如果有朝一日神经网络能够自行设计自己的结构，想必自然语言处理也能进入一个新的境界</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;学习笔记&lt;/p&gt;
&lt;p&gt;《自然语言处理入门》 何晗著 人民邮电出版社&lt;/p&gt;</summary>
    
    
    
    <category term="Book" scheme="http://ljh2000.github.io/categories/Book/"/>
    
    
    <category term="NLP" scheme="http://ljh2000.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>LibDX:A Cross-Platform and Accurate System to Detect Third-Party Libraries in Binary Code</title>
    <link href="http://ljh2000.github.io/2022/10/16/LibDX/"/>
    <id>http://ljh2000.github.io/2022/10/16/LibDX/</id>
    <published>2022-10-16T15:00:06.000Z</published>
    <updated>2022-10-17T13:56:33.629Z</updated>
    
    <content type="html"><![CDATA[<p>论文链接：<a href="https://ieeexplore.ieee.org/document/9054845">LibDX: ACross-Platform and Accurate System to Detect Third-Party Libraries inBinary Code | IEEE Conference Publication | IEEE Xplore</a></p><span id="more"></span><h2 id="摘要">摘要</h2><ul><li>第三方库的大规模使用带来的安全隐患：侵犯许可协议、安全漏洞。</li><li>C/C++的库识别困难在于编译进程隐藏了代码的大部分特征</li><li>同一个开源包可能因为不同的编译进程而编译为不同的二进制代码</li><li>作者推出了LibDX系统，能实现<strong>平台无关</strong>、<strong>全自动</strong>地检测二进制文件中的第三方库调用<ul><li>优秀的特征提取程序，解决了不同二进制文件中的编译差异</li><li>创新地引进了逻辑特征块的概念，能应用于解决超大规模特征数据库下特征再复制的问题</li></ul></li><li>作者建立了来自多个平台的大型数据集，并且使用了包含大量C/C++二进制文件的包测试<ul><li>准确率 92%，召回率97%，达到目前的最高水准</li><li>已使用闭源的商业应用验证，并且发现了一些侵犯许可的案例</li></ul></li></ul><h2 id="导论">导论</h2><ul><li>开源代码网站：Github、SourceForge、Google Code</li><li>包管理软件：APT、RPM、Homebrew、CocoaPods、NuGet</li><li>第三方库的大规模使用减少了开发成本，缩短了开发周期，能让开发者专注于功能开发<ul><li>常用的第三方库调用方式：包含源码、动态链接库、运行可执行文件</li><li>开源库通常会附有调用限制和证书，忽视产权和调用限制的产品往往会造成一些商业纠纷</li><li>广泛使用的公共第三方库漏洞会对用户造成很大安全隐患，并且很多组织并不会频繁更新其调用的第三方库版本</li></ul></li><li>开源代码<ul><li>可以通过现有的源码检测技术来检查复用情况</li><li>但是很多作为商业产品的软件常常是不公开代码的，而且诸如Google-Mobile-Ads-SDK等是闭源库，开发者应用时需要调用编译好的二进制文件，并不能接触源码</li></ul></li><li>二进制文件<ul><li>在以可执行的二进制文件作为发布版本的项目中，编译者将C/C++代码编译成不同操作系统的机器语言代码，例如函数名、变量名、函数调用关系等代码特征在编译时被删去了</li><li>二进制文件的不可靠给特征提取、标记检测带来了极大困难，并且如果错误的特征被用作标记，很可能会造成低匹配率以及假阳样本数</li><li>反编译技术尝试将二进制代码恢复成源码（IDA），但是效果不佳并且很难实现自动化</li><li>平台与环境差异对特征提取和目标检测带来了巨大困扰</li><li>LibDX是首个能覆盖不同平台的检测系统</li></ul></li><li>LibDX能实现多平台兼容、全自动检测，识别第三方库的二进制文件特征，提取特征并为每个第三方库建立标记，从而建立庞大的特征数据库<ul><li>给定检测目标（实际应用，可能封装成任何形式），系统使用跨平台的文件处理程序分析其二进制文件，并提取特征，匹配特征数据库的数据</li><li>创新地引入了逻辑特征块的概念，表示代码的逻辑特征</li><li>识别应用和第三方库中的逻辑特征块，生成目标的基因图谱</li><li>由于代码和特征复用，在原始基因图谱中可能有一些假阳样本</li><li>对于符合同一逻辑特征块的二进制文件，分成一组，从每一组选取最佳的匹配作为检测结果</li></ul></li><li>分析者可以通过第三方库信息数据库，获取关于侵犯协议和漏洞风险的安全报告</li><li>LibDX系统的主要贡献<ul><li>编写了文件处理器和特征提取器，用以分析不同包和二进制形式文件的应用</li><li>创新地采取了二进制文件特征提取方式，建立了第三方库的数据库</li><li>创新地引入了逻辑特征块概念，并用以处理代码和特征复用的情形</li><li>高准确率、高召回率</li></ul></li></ul><h2 id="相关工作与libdx相关的现有技术工作">相关工作（与LibDX相关的现有技术工作）</h2><ul><li><p>所有的库检测系统，本质上说是同源代码检测系统</p></li><li><p>第三方库可以分为两类：C/C++、Java</p><ul><li><p>Java的字节码并非二进制格式，Java包括了很多可用的特征，能很方便检测同源性，所以Java库同源检测技术很难应用于C/C++库</p></li><li><p>C/C++库的检测系统可以分为三类：Source-to-Source、Binary-to-Source、Binary-to-Binary</p></li><li><p>相关商业产品：Insignary、FlexNet Code Insight、Black DuckSCA（都采用的是binary-to-source）</p></li></ul></li></ul><h2 id="概述">概述</h2><ul><li>设计目标<ul><li>大体量，大规模</li><li>跨平台</li><li>全自动</li></ul></li><li>两大主要挑战与困难：不同平台上各种各样的文件格式、大规模数据库产生的特征副本<ul><li>File Format：LibDX采用binary-to-binary的相似度比较</li><li>Feature Duplication</li></ul></li><li>数据<ul><li>关注提供动态链接库文件的packages：libraries-&gt;dynamic link libraryfiles-&gt;features</li><li>9537 packages，包含25794个二进制文件</li></ul></li><li>特征选取<ul><li>稳定且自动化？字符串常量？能同时从源和二进制代码提取的？</li><li>LibDX从库中只读的DATA数据段选取内容作为特征，通常由字符串常量组成</li><li>字符串常量只能表达句法特征，而不能表达代码语义逻辑，作者创新地引入了逻辑特征块来表示语义关系和进一步生成基因图谱，用以目标检测</li><li>LibDX得到最佳匹配结果，并相应给出最终检测结果</li></ul></li><li>权重系数<ul><li>使用TF-IDF系数能反映大数据集下术语在文档中的重要程度</li></ul></li><li>架构<ul><li>File Processor -&gt; Feature Extractor -&gt; Detector</li><li>FileProcessor：接收库的多种格式的包并正确识别文件格式，快速分析目标文件，并提取出二进制文件</li><li>FeatureExtractor：读取不同平台二进制文件中的只读DATA数据段，并提取其特征和模糊的文件名，来建立分层的库信息数据库，匹配目标结果</li><li>LibDX主要使用Python开发，数据存储在MongoDB，并且为每个库和二进制文件分配了ID</li><li>key是字符串，相应的value是key存在的二进制文件list</li></ul></li><li>与类似工作的比较</li></ul><h2 id="系统设计">系统设计</h2><ul><li><p>File Processor</p><ul><li>正确识别文件类型（可能存在的问题：无后缀、相同后缀却是不同类型）</li><li>分为三类：压缩文件（zip、tar）、二进制文件（PE、ELF）和其他文件（txt、png）</li></ul></li><li><p>Feature Extractor</p><ul><li>选取DATA数据段的静态变量作为提取的主要特征</li><li>选取特征序列的标准：以特定串开头结尾、都为可打印字符、长度超过5</li></ul></li><li><p>Logic Feature Block</p><ul><li>字符串常量是句法特征，并不能完全体现代码逻辑</li><li>根据提取的特征数据库，由特征list得到匹配特征块，并将一个匹配块视为一个逻辑特征块<ul><li>至少含有一个positive flag</li><li>没有任何negative flag</li></ul></li><li>编译器建立抽象语法树的依据是解析代码时的逻辑</li></ul></li><li><p>Matching method</p><ul><li><p>上述工作计算了每个库的匹配率，并设置了阈值来决定样本是否为阳性</p></li><li><p>我们对于本地数据库在提取了featurelist后再计算匹配率，以TF-IDF计算权重</p></li><li><p>初步筛选假阳样本的策略：（满足以下条件才合法）</p><ul><li>匹配率大于0.25</li><li>数据集该二进制文件含有超过20个feature</li></ul></li><li><p>上述策略依据：高匹配率+少量的特征数时不可信</p></li><li><p>候选对象根据匹配率排序，底部候选对象的匹配率最高</p></li><li><p>对于被筛选掉的不足20个feature的候选者，进一步检测</p><ul><li><p>如果被动态链接重用，可能会有相同的fuzzy name</p></li><li><p>如果被数据集另一个库包含，不能得到fuzzyname，但是调用的库可以被检测为positive match</p></li></ul></li></ul></li></ul><h2 id="评价">评价</h2><ul><li>用标注好的校准数据集测试</li><li>高准确率、召回率，测试有效</li></ul><h2 id="改进方向">改进方向</h2><ul><li>“不同特征块表示不同代码含义”，这一假设并不总是成立，不同名可能同一意义，在测试数据中有相应的假阳样本</li><li>所得测试结果并不能代表整个开源世界的代码</li><li>漏洞检测仍需改进，并不是所有的库都适用CVE搜索，版本号定位有时非常困难</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;论文链接：&lt;a href=&quot;https://ieeexplore.ieee.org/document/9054845&quot;&gt;LibDX: A
Cross-Platform and Accurate System to Detect Third-Party Libraries in
Binary Code | IEEE Conference Publication | IEEE Xplore&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Paper" scheme="http://ljh2000.github.io/categories/Paper/"/>
    
    
    <category term="KeenLab" scheme="http://ljh2000.github.io/tags/KeenLab/"/>
    
    <category term="SCA" scheme="http://ljh2000.github.io/tags/SCA/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://ljh2000.github.io/2022/10/16/hello-world/"/>
    <id>http://ljh2000.github.io/2022/10/16/hello-world/</id>
    <published>2022-10-16T13:01:36.559Z</published>
    <updated>2022-10-16T13:01:36.559Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your veryfirst post. Check <a href="https://hexo.io/docs/">documentation</a> formore info. If you get any problems when using Hexo, you can find theanswer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> oryou can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><pre class="language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><pre class="language-bash" data-language="bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><pre class="language-bash" data-language="bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><pre class="language-bash" data-language="bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very
first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; fo</summary>
      
    
    
    
    
  </entry>
  
</feed>
